{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## U-net implementation with Tensorflow\n### Matty Vermet","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom tensorflow.keras.layers import Conv2D,BatchNormalization,MaxPool2D,Concatenate,Add,Dropout,ReLU,Conv2DTranspose,UpSampling2D\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T07:39:51.593892Z","iopub.execute_input":"2021-06-17T07:39:51.594275Z","iopub.status.idle":"2021-06-17T07:39:57.812441Z","shell.execute_reply.started":"2021-06-17T07:39:51.594173Z","shell.execute_reply":"2021-06-17T07:39:57.811576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize parameters\nBATCH_SIZE = 30 \nIMG_WIDTH = 224 \nIMG_HEIGHT = 224 \nIMG_CHANNELS = 3\n# wrong = 0\n# threshold = 1 - 0.477\n#threshold_PCA = 54.0\nthreshold_samples = 0.5\n\n# Paths to images and masks \nTRAIN_PATH_IMG_1 = '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images'\nTRAIN_PATH_MASK_1 = '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/masks'\nVAL_PATH_IMG_2 = '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images'\nVAL_PATH_MASK_2 = '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/masks'\nTEST_PATH_IMG_3 = '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images'\nTEST_PATH_MASK_3 = '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/masks'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\n\nids_1 = next(os.walk(TRAIN_PATH_IMG_1))[2]\nids_2 = next(os.walk(VAL_PATH_IMG_2))[2]\nids_3 = next(os.walk(TEST_PATH_IMG_3))[2]\n\nnp.random.seed(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T07:40:00.044741Z","iopub.execute_input":"2021-06-17T07:40:00.045073Z","iopub.status.idle":"2021-06-17T07:40:00.369766Z","shell.execute_reply.started":"2021-06-17T07:40:00.045042Z","shell.execute_reply":"2021-06-17T07:40:00.368017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove outliers\n","metadata":{}},{"cell_type":"code","source":"# Remove outliers from train, validation, test set\nnoise_train = ['../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_584.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_586.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_604.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_748.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_750.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_780.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_811.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_812.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_813.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_828.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_830.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_832.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_833.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_996.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_998.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1147.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1148.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1149.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1152.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1155.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1158.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1160.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1161.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1164.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1166.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1432.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1433.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1512.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1578.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1614.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1615.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1616.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1617.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1618.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1619.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1620.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1629.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1632.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1704.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1705.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1707.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1708.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1709.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1723.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1724.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1725.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1748.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1749.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1750.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1751.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1752.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1753.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1859.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1864.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1870.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1880.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1923.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1939.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1940.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1945.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1946.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1966.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1967.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1968.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1969.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1970.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1971.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1972.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1973.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1974.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1975.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1976.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1977.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1978.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1979.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2007.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2009.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2019.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2020.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2022.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2098.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2108.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2109.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2110.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2111.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2115.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2131.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2132.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2133.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2134.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2135.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2137.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2163.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2164.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2165.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2174.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2176.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2202.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2263.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2264.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2265.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2267.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2406.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2407.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2462.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2463.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2464.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2465.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2515.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2550.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2551.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2552.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2626.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2636.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2639.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2640.npy']\n\nnoise_val =  ['../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_544.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_679.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_680.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_724.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_749.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_750.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_752.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_753.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1028.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1029.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1241.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1248.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1249.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1403.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1404.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1434.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1435.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1436.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1440.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1470.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1471.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1472.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1473.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1474.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1475.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1476.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1477.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1478.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1524.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1526.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1538.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1539.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1540.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1541.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1542.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1543.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1544.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1545.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1546.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1558.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1559.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1560.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1600.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1601.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1607.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1651.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1653.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1657.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1660.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1661.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1662.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1665.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1684.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1685.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1686.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1687.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1688.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1689.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1690.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1691.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1692.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1693.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1694.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1695.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1696.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1697.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1698.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1699.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1700.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1701.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1702.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1738.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1741.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1742.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1743.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1746.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1749.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1845.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1846.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1847.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1848.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1849.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1850.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1851.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1852.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1853.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1876.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1889.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1921.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1928.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1929.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1930.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1931.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1932.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1933.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1936.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1998.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1999.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2000.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2003.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2004.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2005.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2019.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2021.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2268.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2269.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2310.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2315.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2397.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2450.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2494.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2508.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2511.npy']\n\nnoise_test = ['../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_236.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_546.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_735.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_754.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_762.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_778.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_780.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_784.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1016.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1076.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1078.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1079.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1083.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1085.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1088.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1307.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1438.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1506.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1507.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1508.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1509.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1510.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1511.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1518.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1519.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1523.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1566.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1567.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1568.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1569.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1570.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1571.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1572.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1611.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1635.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1636.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1645.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1646.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1647.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1648.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1664.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1665.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1666.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1667.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1668.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1669.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1670.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1743.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1757.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1777.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1779.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1780.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1797.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1803.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1804.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1805.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1832.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1833.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1834.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1835.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1836.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1837.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1838.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1839.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1840.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1841.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1842.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1843.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1844.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1845.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1846.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1847.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1848.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1849.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1850.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1851.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1852.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1853.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1854.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1855.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1856.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1857.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1858.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1859.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1860.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1861.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1862.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1894.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1896.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1897.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1987.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1988.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1989.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1990.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1991.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1992.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2023.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2025.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2026.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2063.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2064.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2065.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2066.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2067.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2074.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2123.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2124.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2138.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2142.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2143.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2373.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2375.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2694.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2695.npy']","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:20:19.604666Z","iopub.execute_input":"2021-06-16T08:20:19.604986Z","iopub.status.idle":"2021-06-16T08:20:19.628733Z","shell.execute_reply.started":"2021-06-16T08:20:19.604955Z","shell.execute_reply":"2021-06-16T08:20:19.628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outliers_train_PCA = ['../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1061.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1726.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1727.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1728.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1729.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1730.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1731.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1751.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1753.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2212.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2267.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2329.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2331.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2377.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2378.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2421.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2422.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2423.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2424.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2425.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2426.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2427.npy']\n\noutliers_val_PCA = ['../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1420.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1548.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1549.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1550.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1552.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1553.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1558.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1572.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1573.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1889.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2064.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2068.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2069.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2167.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2169.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2171.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2172.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2173.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2175.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2224.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2258.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2260.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2261.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2262.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2263.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2264.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2265.npy']\n\noutliers_test_PCA = ['../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1007.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1611.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1612.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1649.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1650.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1651.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1668.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1670.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1700.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2187.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2188.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2317.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2347.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2383.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2384.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2387.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2548.npy']","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:20:21.254714Z","iopub.execute_input":"2021-06-16T08:20:21.255028Z","iopub.status.idle":"2021-06-16T08:20:21.262971Z","shell.execute_reply.started":"2021-06-16T08:20:21.254997Z","shell.execute_reply":"2021-06-16T08:20:21.262099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outliers_train = ['../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_984.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1487.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1513.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1754.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1760.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2305.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2308.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2309.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2310.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2311.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2312.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2414.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2435.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2436.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2439.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2440.npy',\n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2651.npy']\n\noutliers_val = ['../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_492.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1326.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1969.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2150.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2151.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2273.npy',\n '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_2276.npy']\n\noutliers_test = ['../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_866.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1355.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1673.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1783.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2098.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2308.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2309.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2310.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2311.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2332.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2392.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2394.npy',\n '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_2630.npy']\n\ncommon_train = ['../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1753.npy', \n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_1751.npy', \n '../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/images/image_2267.npy']\n\ncommon_val = ['../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1558.npy',\n    '../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/images/image_1889.npy']\n\ncommon_test = ['../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1668.npy', \n    '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1670.npy', \n    '../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/images/image_1611.npy']\n\n# when noise and PCA are use > remove overlap from noise\nnoise_train = list(set(noise_train) - set(common_train))\nnoise_val = list(set(noise_val) - set(common_val))\nnoise_test = list(set(noise_test) - set(common_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:20:23.111868Z","iopub.execute_input":"2021-06-16T08:20:23.112185Z","iopub.status.idle":"2021-06-16T08:20:23.119842Z","shell.execute_reply.started":"2021-06-16T08:20:23.112153Z","shell.execute_reply":"2021-06-16T08:20:23.118935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the training data (Fold 1)","metadata":{}},{"cell_type":"code","source":"# Load train images and corresponding masks from Fold 1\nremoval = outliers_train + noise_train + outliers_train_PCA\n\n# Create empty arrays to store images and masks\nX_train = np.zeros((len(ids_1) - len(removal), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(ids_1) - len(removal), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\ntypes_train = []\n\n# Set counters and list for saving IDs of images\ncount = 0\nindex = 0\nids_train = []\n\nprint('Load train images and masks from FOLD 1 and resize')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(ids_1), total=len(ids_1)):\n    ids_train.append(id_)\n    path = TRAIN_PATH_IMG_1 + '/' + id_\n    \n    if path not in removal:  # Check if image is not an outlier\n        # get numbers from id_\n        number = re.findall(r'\\d+', id_) \n        res = list(map(int, number))\n                \n        # Load type        \n        type_ = np.load( f'../input/nuclei-detection-for-segmentation/Fold__1/Fold_1/content/Fold 1/types/type_{res[0]}.npy')\n        type_ = type_.tolist()\n        types_train.append(type_)       \n\n        # Load image\n        img = np.load(path)\n        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n        X_train[index] = img\n        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n                \n        # Load mask\n        path = TRAIN_PATH_MASK_1 + '/mask_' + str(res[0]) + \".npy\"\n        mask_ = np.load(path, allow_pickle=True)\n        positive_pixel_count = mask_[:,:,5].sum() # assumes binary mask\n        if positive_pixel_count == 0:\n            mask_ = mask_[:,:,5]\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                          preserve_range=True), axis=-1)\n            mask_ = np.array(mask_, dtype=bool).astype(np.uint8)\n            mask = np.maximum(mask, mask_)\n\n            Y_train[index] = mask\n        \n        else:       \n\n            mask_ = mask_[:,:,5]\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                          preserve_range=True), axis=-1)\n\n            mask_ = np.array(mask_, dtype=bool).astype(np.uint8)\n            mask_ = np.where((mask_==0)|(mask_==1), mask_^1, mask_)\n            mask = np.maximum(mask, mask_)\n\n            Y_train[index] = mask\n\n        index += 1\n    else:\n        count += 1\n        \nprint(\"Finished part 1 TRAIN SET\")\nprint(\"noise and outliers: \", count)\nprint(\"Index: \", index)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:20:25.49531Z","iopub.execute_input":"2021-06-16T08:20:25.495643Z","iopub.status.idle":"2021-06-16T08:22:56.185925Z","shell.execute_reply.started":"2021-06-16T08:20:25.495611Z","shell.execute_reply":"2021-06-16T08:22:56.185032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the validation data (Fold 2)","metadata":{}},{"cell_type":"code","source":"# Load validation images and corresponding masks from Fold 2\n\nremoval = outliers_val + noise_val + outliers_val_PCA\n\n# Create empty arays to store images and masks\nX_val = np.zeros((len(ids_2) - len(removal), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_val = np.zeros((len(ids_2) - len(removal), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\ntypes_val = []\n\n# Set counters and list for saving IDs of images\ncount = 0\nindex = 0\nids_val = []\n\nprint('Load validation images and masks from FOLD 2 and resize')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(ids_2), total=len(ids_2)):\n    ids_val.append(id_)\n    path = VAL_PATH_IMG_2 + '/' + id_\n    \n    if path not in removal:   # Check if image is not an outlier\n        # get numbers from id_\n        number = re.findall(r'\\d+', id_) \n        res = list(map(int, number))\n        \n        # Load type        \n        type_ = np.load( f'../input/nuclei-detection-for-segmentation/Fold__2/Fold_2/content/Fold 2/types/type_{res[0]}.npy')\n        type_ = type_.tolist()\n        types_val.append(type_) \n        \n        # load image\n        img = np.load(path)\n        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n        X_val[index] = img\n        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n        \n        # load mask\n        path = VAL_PATH_MASK_2 + '/mask_' + str(res[0]) + \".npy\"\n        mask_ = np.load(path, allow_pickle=True)\n        positive_pixel_count = mask_[:,:,5].sum() # assumes binary mask\n        if positive_pixel_count == 0:\n            mask_ = mask_[:,:,5]\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                          preserve_range=True), axis=-1)\n            mask_ = np.array(mask_, dtype=bool).astype(np.uint8)\n            mask = np.maximum(mask, mask_)\n\n            Y_val[index] = mask\n        \n        else:       \n\n            mask_ = mask_[:,:,5]\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                          preserve_range=True), axis=-1)\n\n            mask_ = np.array(mask_, dtype=bool).astype(np.uint8)\n            mask_ = np.where((mask_==0)|(mask_==1), mask_^1, mask_)\n            mask = np.maximum(mask, mask_)\n\n            Y_val[index] = mask\n        \n        index += 1\n\n\n    else:\n        count += 1\n        \nprint(\"Finished part 2 VAL SET\")\nprint(\"Index: \", index)\nprint(\"noise and outliers: \", count)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:22:37.17843Z","iopub.execute_input":"2021-06-01T11:22:37.178679Z","iopub.status.idle":"2021-06-01T11:24:19.447964Z","shell.execute_reply.started":"2021-06-01T11:22:37.178654Z","shell.execute_reply":"2021-06-01T11:24:19.447202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add image augmentation\n","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing import image\n\n# Creating the training Image and Mask generator\nimage_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\nmask_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\n\n# Keep the same seed for image and mask generators so they fit together\n\nimage_datagen.fit(X_train, augment=True, seed=seed)\nmask_datagen.fit(Y_train, augment=True, seed=seed)\n\nx=image_datagen.flow(X_train,batch_size=BATCH_SIZE,shuffle=True, seed=seed)\ny=mask_datagen.flow(Y_train,batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n\n\n# Creating the validation Image and Mask generator\nimage_datagen_val = image.ImageDataGenerator()\nmask_datagen_val = image.ImageDataGenerator()\n\nimage_datagen_val.fit(X_val, augment=True, seed=seed)\nmask_datagen_val.fit(Y_val, augment=True, seed=seed)\n\nx_val=image_datagen_val.flow(X_val,batch_size=BATCH_SIZE,shuffle=True, seed=seed)\ny_val=mask_datagen_val.flow(Y_val,batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n\ntrain_generator = zip(x, y)\nval_generator = zip(x_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:33:16.297192Z","iopub.execute_input":"2021-06-01T11:33:16.297527Z","iopub.status.idle":"2021-06-01T11:33:54.149557Z","shell.execute_reply.started":"2021-06-01T11:33:16.297499Z","shell.execute_reply":"2021-06-01T11:33:54.148538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set evalutation metrics","metadata":{}},{"cell_type":"code","source":"smooth = K.epsilon()\nthreshold = 0.5\nlabel_smoothing = 0.0\nbce_weight = 0.5\n\ndef iou(y_true, y_pred):\n    overlap = tf.math.logical_and((y_true > threshold),(y_pred > threshold))\n    union = tf.math.logical_or((y_true > threshold),(y_pred > threshold))\n    iou = (tf.cast(tf.math.count_nonzero(overlap),tf.float32) + smooth) / (tf.cast(tf.math.count_nonzero(union),tf.float32) + smooth)\n    return iou\n\ndef jaccard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)    \n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    return (intersection +1.0) / (K.sum(y_true) + K.sum(y_pred) - intersection + 1.0)\n\ndef jaccard_coef_loss(y_true, y_pred):\n    return -jaccard_coef(y_true, y_pred)\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    #y_pred = y_pred[y_pred > threshold].astype('uint8')\n    #y_true = y_true[y_true > threshold].astype('uint8')\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return K.mean( (2. * intersection + smooth) / (union + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:23:03.747084Z","iopub.execute_input":"2021-06-16T08:23:03.747412Z","iopub.status.idle":"2021-06-16T08:23:03.759319Z","shell.execute_reply.started":"2021-06-16T08:23:03.747379Z","shell.execute_reply":"2021-06-16T08:23:03.758505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Implement U-net model\n\nsource: https://towardsdatascience.com/nucleus-segmentation-using-u-net-eceb14a9ced4","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:34:09.864876Z","iopub.execute_input":"2021-06-01T11:34:09.865176Z","iopub.status.idle":"2021-06-01T11:34:10.757299Z","shell.execute_reply.started":"2021-06-01T11:34:09.865148Z","shell.execute_reply":"2021-06-01T11:34:10.75642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile and run model","metadata":{}},{"cell_type":"code","source":"model = Model(inputs=[inputs], outputs=[outputs], name=\"UNET\")\n# epochs=10\n# learning_rate = 0.0001\n# decay_rate = learning_rate / epochs\n# momentum = 0.8\n# adam = Adam(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou, jaccard_coef, dice_coef])\nmodel.summary()\n\n# # define the learning rate change \n# def exp_decay(epoch):\n#     lrate = learning_rate * np.exp(-decay_rate*epoch)\n#     return lrate\n    \n# # learning schedule callback\n# loss_history = History()\n# lr_rate = LearningRateScheduler(exp_decay)\n# callbacks_list = [loss_history, lr_rate, checkpointer]\n\n#earlystopper = EarlyStopping(patience=3, verbose=1)\ncheckpointer = ModelCheckpoint('model-UNET-1.h5', verbose=1, save_best_only=True)\nresults = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=250,\n                              epochs=40, callbacks=[checkpointer])","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:34:12.968435Z","iopub.execute_input":"2021-06-01T11:34:12.968746Z","iopub.status.idle":"2021-06-01T11:39:45.026845Z","shell.execute_reply.started":"2021-06-01T11:34:12.968718Z","shell.execute_reply":"2021-06-01T11:39:45.025533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot evaluation metrics and loss vs epochs\n","metadata":{}},{"cell_type":"code","source":"print(results.history.keys())\n\nfigure, axes = plt.subplots(nrows=3, ncols=1, figsize=(12,7))\naxes[0].plot(results.history['loss'])\naxes[0].plot(results.history['val_loss'])\naxes[0].legend([\"train\", \"val\"])\naxes[0].set_xlabel('epoch')\naxes[0].set_ylabel('Jaccard loss')\n\naxes[1].plot(results.history['jaccard_coef'])\naxes[1].plot(results.history['val_jaccard_coef'])\naxes[1].legend([\"train\", \"val\"])\naxes[1].set_xlabel('epoch')\naxes[1].set_ylabel('Jaccard')\n\naxes[2].plot(results.history['dice_coef'])\naxes[2].plot(results.history['val_dice_coef'])\naxes[2].legend([\"train\", \"val\"])\naxes[2].set_xlabel('epoch')\naxes[2].set_ylabel('F1')\n\nfigure.suptitle('Performance metrics in relation to epoch')","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:40:25.235624Z","iopub.execute_input":"2021-06-01T11:40:25.235962Z","iopub.status.idle":"2021-06-01T11:40:25.672202Z","shell.execute_reply.started":"2021-06-01T11:40:25.235929Z","shell.execute_reply":"2021-06-01T11:40:25.670841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the test data","metadata":{}},{"cell_type":"code","source":"removal = outliers_test + noise_test + outliers_test_PCA\n\n# Create empty arrays to store images and masks\nX_test = np.zeros((len(ids_3) - len(removal), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_test = np.zeros((len(ids_3) - len(removal), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\ntypes_test = []\n\n# Set counters and list for saving IDs of images\ncount_test = 0\nindex = 0\nids_test = []\nsizes_test = []\n\n\nprint('Load test images and masks from FOLD 3 and resize')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(ids_3), total=len(ids_3)):\n    \n    path = TEST_PATH_IMG_3 + '/' + id_\n    \n    if path not in removal:  # Check if image is not an outlier\n        ids_test.append(id_)\n        # get numbers from id_\n        number = re.findall(r'\\d+', id_) \n        res = list(map(int, number))\n        \n        # Load type        \n        type_ = np.load( f'../input/nuclei-detection-for-segmentation/Fold__3/Fold_3/content/Fold 3/types/type_{res[0]}.npy')\n        type_ = type_.tolist()\n        types_test.append(type_)       \n\n        # Load image\n        img = np.load(path)\n        sizes_test.append([img.shape[0], img.shape[1]])\n        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n        X_test[index] = img\n        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n                \n        # Load mask\n        path = TEST_PATH_MASK_3 + '/mask_' + str(res[0]) + \".npy\"\n        mask_ = np.load(path, allow_pickle=True)\n        \n        positive_pixel_count = mask_[:,:,5].sum() # assumes binary mask\n        if positive_pixel_count == 0:\n            mask_ = mask_[:,:,5]\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                          preserve_range=True), axis=-1)\n            mask_ = np.array(mask_, dtype=bool).astype(np.uint8)\n            mask = np.maximum(mask, mask_)\n\n            Y_test[index] = mask\n        \n        else:       \n\n            mask_ = mask_[:,:,5]\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                          preserve_range=True), axis=-1)\n\n            mask_ = np.array(mask_, dtype=bool).astype(np.uint8)\n            mask_ = np.where((mask_==0)|(mask_==1), mask_^1, mask_)\n            mask = np.maximum(mask, mask_)\n\n            Y_test[index] = mask\n\n        index += 1\n    else:\n        count_test += 1\n        \nprint(\"Finished TEST SET\")\nprint(\"Noise and outliers: \", count_test)\nprint(\"Index: \", index)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:23:09.714658Z","iopub.execute_input":"2021-06-16T08:23:09.714971Z","iopub.status.idle":"2021-06-16T08:25:50.273995Z","shell.execute_reply.started":"2021-06-16T08:23:09.714941Z","shell.execute_reply":"2021-06-16T08:25:50.273054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create predictions","metadata":{}},{"cell_type":"code","source":"custom_obj = {}\n#custom_obj['jaccard_coef_loss'] = jaccard_coef_loss\ncustom_obj['jaccard_coef'] = jaccard_coef\ncustom_obj['dice_coef'] = dice_coef\ncustom_obj['dice_coef_loss'] = dice_coef_loss\ncustom_obj['iou'] = iou\n\n# Define model\nmodel = load_model('../input/unet-diceloss/model-UNET-diceloss.h5', custom_objects = custom_obj)\npreds_train = model.predict(X_train, verbose=1)\n#preds_val = model.predict(X_val, verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\n#preds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:29:11.294371Z","iopub.execute_input":"2021-06-16T08:29:11.29472Z","iopub.status.idle":"2021-06-16T08:29:22.782554Z","shell.execute_reply.started":"2021-06-16T08:29:11.294689Z","shell.execute_reply":"2021-06-16T08:29:22.781718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check robustness of predctions (F1-score and Jaccard score)","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import jaccard_score\n\nf1_scores = []\njaccard_scores = []\nthreshold = []\nfinal_f1 = []\nfinal_jaccard = []\n\n#print(\"Training time: \", end-start)\nprint(\"len pred: \",len(preds_train_t))\nprint(\"len y_train: \",len(Y_train))\n\nfor thres in range(0, 105, 5):\n    thres_ = thres/100\n    threshold.append(thres_)\n    preds_test_t = (preds_test > thres_).astype(np.uint8)\n    \n    f1_scores = []\n    jaccard_scores = []\n                    \n    for i in range(0, len(Y_test)):\n\n        f1 = f1_score(Y_test[i].reshape(-1), preds_test_t[i].reshape(-1))\n        f1_scores.append(f1)\n        jacc = jaccard_score(Y_test[i].reshape(-1), preds_test_t[i].reshape(-1))\n        jaccard_scores.append(jacc)\n    \n    final_f1.append(sum(f1_scores)/len(Y_test))\n    final_jaccard.append(sum(jaccard_scores)/len(Y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Processing of the predictions for calculation of PQ and Cell-Counting Accuracy\n","metadata":{}},{"cell_type":"code","source":"before = np.copy(preds_test_t)\n\nfor i in range(0, len(preds_test_t)):\n    before[i] = np.where(before[i]==1, (Y_test_panoptic[i]*2 + before[i]), before[i])\n\nfor i in range(0, len(before)):\n    before[i] = np.where(before[i] > 1, before[i] -1 , before[i])\n\ntrial = np.copy(before)\n\nshape_ = trial.shape\nprint(shape_)\n\nfor x in range(0, 4):\n    print(x)\n    for i in range(0, shape_[0]):\n        trial[i] = np.rot90(trial[i])\n\n        for row in range(0, shape_[1]):\n            for col in range(0, shape_[2]):\n                if trial[i][row][col] == 1:\n                    if row != 223 and trial[i][row+1][col] not in (1, 0):\n                        trial[i][row][col] = trial[i][row+1][col]\n                    elif row != 0 and trial[i][row-1][col] not in (1, 0):\n                        trial[i][row][col] = trial[i][row-1][col]\n                    elif col != 223 and trial[i][row][col+1] not in (1,0):\n                        trial[i][row][col] = trial[i][row][col+1]                         \n                    elif col != 0 and trial[i][row][col-1] not in (1, 0):\n                        trial[i][row][col] = trial[i][row][col-1]\n                    \n                    elif row not in (223,222) and trial[i][row+2][col] not in (1, 0):\n                        trial[i][row][col] = trial[i][row+2][col]\n                    elif col not in (222,223) and trial[i][row][col+2] not in (1,0):\n                        trial[i][row][col] = trial[i][row][col+2]\n                    elif row not in (0,1) and trial[i][row-2][col] not in (1, 0):\n                        trial[i][row][col] = trial[i][row-2][col]\n                    elif col not in (0,1) and trial[i][row][col-2] not in (1,0):\n                        trial[i][row][col] = trial[i][row][col-2]\n                        \n                    elif row not in (223,222,221) and trial[i][row+3][col] not in (1, 0):\n                        trial[i][row][col] = trial[i][row+3][col]                 \n                    elif row not in (0,1,2) and trial[i][row-3][col] not in (1, 0):\n                        trial[i][row][col] = trial[i][row-3][col]                   \n                    elif col not in (222,223,221) and trial[i][row][col+3] not in (1,0):\n                        trial[i][row][col] = trial[i][row][col+3]\n                    elif col not in (0,1,2) and trial[i][row][col-3] not in (1,0):\n                        trial[i][row][col] = trial[i][row][col-3]\n                    else:\n                        trial[i][row][col] = trial[i][row][col]\n                        \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cell-Counting Accuracy calculation\n","metadata":{}},{"cell_type":"code","source":"# BASED ON: https://stackoverflow.com/questions/58751101/count-number-of-cells-in-the-image\nimport copy\n\nlen_contour_list_true = []\nafter_thresholds_true = []\narea_nuclei = []\n\nexample = 70\n\nfor i in range(0, len(Y_test)):\n\n    mask = (Y_test_panoptic[i]*2).astype('uint8')    \n    img  = np.copy(X_test[i])\n    drawing = np.copy(img)\n    count_cnts = 0\n\n    IDs = np.unique(mask)\n    for ID in IDs:\n        if ID != 0:\n            mask_per_id = np.copy(mask)\n            for x in range(0, len(mask)):                \n                mask_per_id[x] = np.where(mask[x] != ID, 0, mask[x])\n\n            cnts = cv2.findContours(mask_per_id, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n            \n            count_cnts += len(cnts)            \n            \n            #cv2.drawContours(drawing, cnts, -1, (0, 255, 0), thickness=3)\n\n    len_contour_list_true.append(count_cnts)\n    \n#     figure, (ax3, ax4) = plt.subplots(1,2, figsize=(10,10))\n#     ax1.imshow(mask * 255)\n#     print(\"nr of nuclei true: \", count_cnts)\n\n    # count nuclei area for every image in test set\n    for c in cnts:\n        area = cv2.contourArea(c)\n        area_nuclei.append(area)\n\n\n#### PREDICTED MASK ####\n\nlen_contour_list_pred = []\nafter_thresholds_pred = []\n\nfor i in range(0, len(Y_test)):\n\n    mask_ = trial[i].astype('uint8')    \n    img_  = np.copy(X_test[i])\n    count_cnts = 0\n\n    IDs = np.unique(mask_)\n    for ID in IDs:\n        if ID != 0:\n            mask_per_id = np.copy(mask_)\n            for x in range(0, len(mask_)):                \n                mask_per_id[x] = np.where(mask_[x] != ID, 0, mask_[x])\n\n            cnts = cv2.findContours(mask_per_id, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n            \n            count_cnts += len(cnts)\n            \n#             cv2.drawContours(drawing, cnts, -1, (255,0,0), thickness=2)\n            \n    len_contour_list_pred.append(count_cnts)\n#     print(\"nr of nuclei pred: \", count_cnts)\n\n\n#     ax2.imshow(mask_ * 255)\n#     ax4.imshow(drawing)\n#     ax4.set_title('U-net (red) vs GT (green)', fontsize=15)\n#     ax4.axis('off')\n#     ax3.imshow(img_)\n#     ax3.set_title('Example image',  fontsize=15)\n#     ax3.axis('off')\n\n#     ax2.plot(cnts_)\n#     print(cnts_)\n\nabs_diff = []\nfor i in range(0, len(len_contour_list_true)):\n    if len_contour_list_true[i] is not 0:\n        abs_diff.append((abs(len_contour_list_true[i] - len_contour_list_pred[i]) / len_contour_list_true[i]))\n\nprint(\"mean of abs diff: \", statistics.mean(abs_diff))\nprint(\"max abs diff: \", max(abs_diff))\nprint(\"min abs diff: \", min(abs_diff))\nprint(\"Cell-counting accuracy: \", 1-statistics.mean(abs_diff))\nprint(\"std of abs diff: \", statistics.stdev(abs_diff))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculation of PQ\nsource: https://www.kaggle.com/ipateam/u-net-with-binary-labels","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import jaccard_score\n\ndef get_fast_pq(true, pred, match_iou=0.5):\n    \"\"\"\n    `match_iou` is the IoU threshold level to determine the pairing between\n    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n    if IoU > `match_iou`. However, pair of `p` and `g` must be unique\n    (1 prediction instance to 1 GT instance mapping).\n    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n    in bipartite graphs) is caculated to find the maximal amount of unique pairing.\n    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n    the number of pairs is also maximal.\n    Fast computation requires instance IDs are in contiguous orderding\n    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand\n    and `by_size` flag has no effect on the result.\n    Returns:\n        [dq, sq, pq]: measurement statistic\n        [paired_true, paired_pred, unpaired_true, unpaired_pred]:\n                      pairing information to perform measurement\n    \"\"\"\n    assert match_iou >= 0.0, \"Cant' be negative\"\n    \n    positive_pixel_count = true.sum()\n    \n    if positive_pixel_count == 0 :\n        print('positive = 0')\n        return None\n    \n    \n    else:\n    \n        true = np.copy(true)\n        pred = np.copy(pred)\n        true_id_list = list(np.unique(true))\n        pred_id_list = list(np.unique(pred))\n\n        true_masks = [None, ]\n        for t in true_id_list[1:]:\n            t_mask = np.array(true == t, np.uint8)\n            true_masks.append(t_mask)\n\n        pred_masks = [None, ]\n        for p in pred_id_list[1:]:\n            p_mask = np.array(pred == p, np.uint8)\n            pred_masks.append(p_mask)\n\n        # prefill with value\n        pairwise_iou = np.zeros([len(true_id_list) - 1,\n                                 len(pred_id_list) - 1], dtype=np.float64)\n\n        # caching pairwise iou\n        for true_id in true_id_list[1:]:  # 0-th is background\n            t_mask = true_masks[true_id]\n            pred_true_overlap = pred[t_mask > 0]\n            pred_true_overlap_id = np.unique(pred_true_overlap)\n            pred_true_overlap_id = list(pred_true_overlap_id)\n            for pred_id in pred_true_overlap_id:\n                if pred_id == 0:  # ignore\n                    continue  # overlaping background\n                p_mask = pred_masks[pred_id]\n                total = (t_mask + p_mask).sum()\n                inter = (t_mask * p_mask).sum()\n                iou = inter / (total - inter)\n                pairwise_iou[true_id - 1, pred_id - 1] = iou\n        #\n        if match_iou >= 0.5:\n            paired_iou = pairwise_iou[pairwise_iou > match_iou]\n            pairwise_iou[pairwise_iou <= match_iou] = 0.0\n            paired_true, paired_pred = np.nonzero(pairwise_iou)\n            paired_iou = pairwise_iou[paired_true, paired_pred]\n            paired_true += 1  # index is instance id - 1\n            paired_pred += 1  # hence return back to original\n        else:  # * Exhaustive maximal unique pairing\n            #### Munkres pairing with scipy library\n            # the algorithm return (row indices, matched column indices)\n            # if there is multiple same cost in a row, index of first occurence\n            # is return, thus the unique pairing is ensure\n            # inverse pair to get high IoU as minimum\n            paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n            ### extract the paired cost and remove invalid pair\n            paired_iou = pairwise_iou[paired_true, paired_pred]\n\n            # now select those above threshold level\n            # paired with iou = 0.0 i.e no intersection => FP or FN\n            print(paired_true)\n            paired_true = list(paired_true[paired_iou > match_iou] + 1)\n            paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n            paired_iou = paired_iou[paired_iou > match_iou]\n\n        # get the actual FP and FN\n        unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n        unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n        # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n\n        #\n        tp = len(paired_true)\n        fp = len(unpaired_pred)\n        fn = len(unpaired_true)\n\n\n        # get the F1-score i.e DQ\n        dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n        #dq = f1_score(true.reshape(-1), pred.reshape(-1))\n       \n        # get the SQ, no paired has 0 iou so not impact\n        sq = paired_iou.sum() / (tp + 1.0e-6)\n        \n\n        return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:40:01.320472Z","iopub.execute_input":"2021-06-16T08:40:01.320827Z","iopub.status.idle":"2021-06-16T08:40:01.339512Z","shell.execute_reply.started":"2021-06-16T08:40:01.320796Z","shell.execute_reply":"2021-06-16T08:40:01.338699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate and plot wrong predicted pixels for example images","metadata":{}},{"cell_type":"code","source":"wrong_pixels = np.zeros((len(ids_3) - len(removal), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\nfor i in range(0, len(wrong_pixels)):\n    \n    wrong_pixels[i] = Y_test[i] - preds_test_t[i]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:46:05.972583Z","iopub.execute_input":"2021-06-16T08:46:05.972926Z","iopub.status.idle":"2021-06-16T08:46:06.090667Z","shell.execute_reply.started":"2021-06-16T08:46:05.972899Z","shell.execute_reply":"2021-06-16T08:46:06.089654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(4, 4, figsize=(20,20))\n\nexample1 = 15\naxs[0,0].imshow(X_test[example1])\naxs[0,0].set_title('Image '+types_train[example1]+'', fontsize=15)\naxs[0,1].imshow(Y_test[example1]*255 ,cmap='gray', vmin=0, vmax=255)\naxs[0,1].set_title('Ground truth', fontsize=15)\naxs[0,2].imshow(preds_test_t[example1]*255,cmap='gray', vmin=0, vmax=255)\naxs[0,2].set_title('U-net', fontsize=15)\naxs[0,3].imshow(wrong_pixels[example1].astype('uint8')*255, vmin=0, vmax=255)\naxs[0,3].set_title('Wrong predicted pixels', fontsize=15)\n\nexample2 = 12\naxs[1,0].imshow(X_test[example2])\naxs[1,0].set_title('Image '+types_train[example2]+'', fontsize=15)\naxs[1,1].imshow(Y_test[example2]*255 ,cmap='gray', vmin=0, vmax=255)\naxs[1,1].set_title('Ground truth', fontsize=15)\naxs[1,2].imshow(preds_test_t[example2]*255,cmap='gray', vmin=0, vmax=255)\naxs[1,2].set_title('U-net', fontsize=15)\naxs[1,3].imshow(wrong_pixels[example2].astype('uint8')*255, vmin=0, vmax=255)\naxs[1,3].set_title('Wrong predicted pixels', fontsize=15)\n\nexample3 = 100\naxs[2,0].imshow(X_test[example3])\naxs[2,0].set_title('Image '+types_train[example3]+'', fontsize=15)\naxs[2,1].imshow(Y_test[example3]*255 ,cmap='gray', vmin=0, vmax=255)\naxs[2,1].set_title('Ground truth', fontsize=15)\naxs[2,2].imshow(preds_test_t[example3]*255,cmap='gray', vmin=0, vmax=255)\naxs[2,2].set_title('U-net', fontsize=15)\naxs[2,3].imshow(wrong_pixels[example3].astype('uint8')*255, vmin=0, vmax=255)\naxs[2,3].set_title('Wrong predicted pixels', fontsize=15)\n\nexample4 = 1000\naxs[3,0].imshow(X_test[example4])\naxs[3,0].set_title('Image '+types_train[example4]+'', fontsize=15)\naxs[3,1].imshow(Y_test[example4]*255 ,cmap='gray', vmin=0, vmax=255)\naxs[3,1].set_title('Ground truth', fontsize=15)\naxs[3,2].imshow(preds_test_t[example4]*255,cmap='gray', vmin=0, vmax=255)\naxs[3,2].set_title('U-net', fontsize=15)\naxs[3,3].imshow(wrong_pixels[example4].astype('uint8')*255, vmin=0, vmax=255)\naxs[3,3].set_title('Wrong predicted pixels', fontsize=15)\n\nfig.savefig('./example_pred_Unet.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:46:07.974746Z","iopub.execute_input":"2021-06-16T08:46:07.975056Z","iopub.status.idle":"2021-06-16T08:46:10.253048Z","shell.execute_reply.started":"2021-06-16T08:46:07.975027Z","shell.execute_reply":"2021-06-16T08:46:10.252009Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
